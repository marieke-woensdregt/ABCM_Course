{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5afcc25",
   "metadata": {},
   "source": [
    "# Take-home assignment: Agent-based Cognitive Modelling\n",
    "\n",
    "Please complete each of the conceptual questions in a markdown cell (in written text), and each of the coding questions using code cells (in combination with markdown cells if a written part is also required for answering the question).\n",
    "\n",
    "It is important that you complete each of the exercises in this take-home assignment **individually**. If we see signs of answers being shared between students, we will investigate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2343fca",
   "metadata": {},
   "source": [
    "**Exercise 1 (Conceptual question):**\n",
    "\n",
    "This question is about agent-based cognitive modelling in general.\n",
    "\n",
    "Below are four research questions. For each of these, write down: \n",
    "- Whether or not you think _agent-based_ modelling would be a sensible approach to address that research question, and explain why. \n",
    "- If your answer is that agent-based modelling would be a sensible approach, also write down whether the agents in this model would have to be _cognitive_ agents, and explain why.\n",
    "\n",
    "1. Is categorisation in humans exemplar-based or feature-based? (In simple terms, _exemplar-based_ means: if a novel stimulus is similar to other dogs I've seen, it's probably a dog. While _feature-based_ means: if it barks, has four legs, and a wagging tail, it's probably a dog.)\n",
    "\n",
    "\n",
    "2. Do more extreme ideas spread through a population more quickly than more moderate ideas?\n",
    "\n",
    "\n",
    "3. When two individuals do a task like moving a sofa together (i.e., _joint action_), how do they coordinate?\n",
    "\n",
    "\n",
    "4. How does eye colour spread through a population? (Assuming, for example, that the allele for blue eyes is recessive and the allele for brown eyes is dominant.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c147358",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e04c9aa",
   "metadata": {},
   "source": [
    "**Exercise 2 (Conceptual question):**\n",
    "\n",
    "This question is about game theory and pay-off matrices as a representation of social coordination situations.\n",
    "\n",
    "Imagine the following situation:\n",
    "- An employer has to make a decision about whether to pay their employee a low or a high salary, without knowing how much effort the employee is going to put into their work. If the employee puts in a high amount of effort, the high salary is worth it. If, instead, the employee puts in a low amount of effort, it's better (from the employer's point of view) to pay them a low salary.\n",
    "- Simultaneously, the employee has to make a decision about whether to put high effort or low effort into their work, without knowing how much the employer is going to pay them. If the employer decides to pay them a high salary, the high amount of effort is worth it. If, instead, the employer decides to pay them a low salary, it's better (from the employee's point of view) to put in a low amount of effort.\n",
    "\n",
    "Below is an empty pay-off matrix (game-theory style). Translate the situation above to a pay-off matrix, by filling in each of the cells in the table below, according to the situation described above. Replace each of the A's and B's in the table with the pay-off values for player A (the employer) and Player B (the employee), using the following values: $[0, 1, 2, 3]$ . Also write out and explain your considerations that went into deciding which numbers to put in each cell of the pay-off matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78436a3",
   "metadata": {},
   "source": [
    "| B (Employee):     | High effort | Low effort |\n",
    "|-------------------|-------------|------------|\n",
    "| **A (Employer):** |             |            |\n",
    "| **High salary**   |     A, B    |    A, B    |\n",
    "| **Low salary**    |     A, B    |    A, B    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e4b4b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5c445b0",
   "metadata": {},
   "source": [
    "**Exercise 3 (Coding question):**\n",
    "\n",
    "Use the tomsup package to simulate the following situation:\n",
    "\n",
    "- agent0 = A ```'1-ToM'``` agent with default parameter settings\n",
    "- agent1 = A ```'2-ToM'``` agent with default parameter settings\n",
    "- game = ```'party'```\n",
    "- environment = ```'round-robin'```\n",
    "- n_sim = 10\n",
    "\n",
    "Run 10 simulations of this interaction for a number of rounds that seems reasonable to you, and use the ```group.plot_p_k()``` method to plot how agent1's belief about agent0's ToM level changes over time. (The three code cells below make a start by loading in the relevant packages.)\n",
    "\n",
    "Find out whether there is a certain number of rounds after which each of the 10 simulations reaches a point where agent1 has a fully accurate model of their opponent's _k_-level (and has reached maximum certainty about that).\n",
    "\n",
    "Show a plot to back up your answer, and also explain your answer fully in words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab375d54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T21:10:42.600807Z",
     "start_time": "2022-10-21T21:10:38.880158Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tomsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae95a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T21:10:44.273383Z",
     "start_time": "2022-10-21T21:10:42.615704Z"
    }
   },
   "outputs": [],
   "source": [
    "import tomsup as ts\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641b5f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T21:10:44.288004Z",
     "start_time": "2022-10-21T21:10:44.284980Z"
    }
   },
   "outputs": [],
   "source": [
    "party = ts.PayoffMatrix(name='party')\n",
    "\n",
    "print(party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e1f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c4d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9debb0b4",
   "metadata": {},
   "source": [
    "**Exercise 4 (Conceptual question):**\n",
    "\n",
    "This question is about both Waade et al. (2022) and de Weerd et al. (2015), and the comparison between these two models.\n",
    "\n",
    "In both the Waade et al. (2022) model and the de Weerd et al. (2015) model, the $k$-ToM agent has a belief about the $k$-level of the agent they're interacting with, and updates this belief over the course of the interactions. Describe the main similarities and differences in how this belief-updating about the other agent's $k$-level works in these two different models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcea2dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79e19d1d",
   "metadata": {},
   "source": [
    "**Exercise 5 (Conceptual question):**\n",
    "\n",
    "This question is about de Weerd et al. (2015).\n",
    "\n",
    "Imagine you want to know whether actual humans adapt their strategy in the Tacit Communication Game depending on their estimate of the level of ToM that their interlocutor uses. Imagine that your experiment consists of the following two conditions (where in both conditions, the participant is _told_ that they are playing the game with another participant, even though in reality, their interlocutor is being simulated by a computer): \n",
    "- In the _0-ToM_ condition, participants interact with a computer that is implemented as a zero-order ToM agent from the de Weerd et al. (2015) model.\n",
    "- In the _1-ToM_ condition, participants interact with a computer that is implemented as a 1st-order ToM agent from the de Weerd et al. (2015) model.\n",
    "\n",
    "Now imagine that you have collected your experimental data and you are ready to analyse your results. These are the specific hypotheses you would like to test:\n",
    "\n",
    "- _Null hypothesis_: Human participants do not adapt their communication strategy to the ToM-level of their interlocutor, and will always behave like a 2-ToM sender.\n",
    "- _Alternative hypothesis_: Human participants _do_ adapt their communication strategy to the ToM-level of their interlocutor. Specifically, participants in the _0-ToM_ condition will behave more like a _1-ToM_ sender, and human participants in the _1-ToM_ condition will behave more like a _2-ToM_ sender.\n",
    "\n",
    "Explain how you could use the model described in de Weerd et al. (2015) to test these hypotheses, _using_ the data you've collected in your experiment as described above. Describe the process step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ca1a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da486c7e",
   "metadata": {},
   "source": [
    "**Exercise 6 (Implementation/code-related question):**\n",
    "\n",
    "This question is about Cuskley et al. (2018).\n",
    "\n",
    "Imagine that you want to extend the Cuskley et al. (2018) model to look at the effect of social network structure on morphological complexity. To give you an idea of what this might look like, three different possible social network types are described at the bottom of this exercise (```\"fully_connected\"```, ```small-world``` and ```\"scale-free\"```). Describe _in words_ how you would have to adapt the code of Computer Lab 3 in order to be able to create populations with these three different social network types. More specifically, answer the three questions below:\n",
    "\n",
    "**a)** How would you go about giving structure to the population (i.e., specifying which agent is connected with which other agents)? The code in Computer Lab 3 consists of several different classes, what attributes would you have to add to which of these classes in order to create such structure?\n",
    "\n",
    "\n",
    "**b)** Assuming you have now added attributes to the relevant classes in order to specify for each agent to which other agents in the population it is connected. To which class would you have to add a method that can initialise a population with a specified type of social network structure (i.e., a method that takes the type of social network structure as one of its input arguments; an input argument that can be set to ```\"fully_connected\"```, ```small-world``` or ```\"scale-free\"```)?\n",
    "\n",
    "\n",
    "**c)** Finally, once you've specified steps **a)** and **b)**, which method of which class would you have to adapt to make sure that agents only interact with agents they are connected to?\n",
    "\n",
    "\n",
    "_Fully connected network_: This network is maximally dense, such that all possible connections are realized (i.e., all agents in the population get to interact with each other). It is also homogenous, in the sense that every agent has the same number of connections.\n",
    "\n",
    "_Small-world network_: This network is also relatively homogenous such that every agent has approximately the same number of connections, yet it is much sparser than the fully connected network and realizes only half of the possible connections. This network type has the small-world property of \"strangers\" being indirectly linked by a short chain of individuals. \n",
    "\n",
    "_Scale-free network_: This network is equally sparse as the small-world network, and it has the same number of possible connections overall. However, it is not homogenous: not every agent has the same number of connections. While some agents are highly connected, others are more isolated. The distribution of connections in this network roughly follows a power-law distribution, with few agents having many connections (forming \"hubs\" who interact with almost everyone in the population), and a tail of agents having very few connections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ee4bad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a36c0ce3",
   "metadata": {},
   "source": [
    "**Exercise 7 (Coding question):**\n",
    "\n",
    "This question is about Mudd et al. (2022).\n",
    "\n",
    "Imagine that you'd want to adapt the model of Mudd et al. (2022) to change the way in which agents update their vocabulary when they find out that they are using two different forms for the same concept. Instead of only the receiver doing _bit update_ to make their form more similar to that of the sender, you want to adapt the model such that _both_ the sender and the receiver update their language representation by adapting to each other; specifically, by finding a middle ground between their two forms. (Like two speakers of English who start out with the two different forms _sofa_ and _couch_, and adapt by both updating their form to a middle ground form like _souch_.)\n",
    "\n",
    "Below is an empty skeleton of a function called ```update_forms()```. Complete this function so that it finds a middle ground between the producer's form and the comprehender's form, and updates both the producer's and the comprehender's language representation with this new form. **Note** that the resulting form that the two agents update their language representation with should still (or again) be a vector containing bits (i.e., only 0s and 1s). (Because changing this to continuous values would require more extensive changes to the rest of the code and model.)\n",
    "\n",
    "_For context:_ this new ```update_forms()``` function would be replacing the ```update_comprehender_concept()``` function (final code cell in section 1.3 of Computer Lab 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9fb4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T21:43:58.819803Z",
     "start_time": "2022-10-21T21:43:58.816700Z"
    }
   },
   "outputs": [],
   "source": [
    "# CODE SKELETON TO COMPLETE FOR EXERCISE 7:\n",
    "\n",
    "# DEFINITIONS:\n",
    "# producer.language_rep[producer_concept_choice][1] = producer's form for the current concept, as in Lab 4\n",
    "# comprehender.language_rep[producer_concept_choice][1]) = comprehender's form for the current concept, as in Lab 4\n",
    "\n",
    "def update_forms(producer, producer_concept_choice, comprehender):\n",
    "    # Step 1: Find the middle ground between the producer's form and the comprehender's form:\n",
    "    \n",
    "    # NOTE: Before moving on to Step 2, make sure that the middle ground form created above is \n",
    "    # (or gets converted back into) a bit vector (i.e., containing only 0s and 1s)\n",
    "    \n",
    "    # Step 2: Update the producer's and comprehender's language representations to the new form:\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f078c46",
   "metadata": {},
   "source": [
    "**Exercise 8 (Model design question):**\n",
    "\n",
    "This question is about agent-based cognitive modelling in general.\n",
    "\n",
    "Below is a research question, followed by a verbal explanation of what this research question is trying to get at. How would you design an agent-based model to answer this research question? (More specific instructions for what to specify follow below.)\n",
    "\n",
    "_Research question:_ What is more important for successful problem-solving: expertise or diversity?\n",
    "\n",
    "_Explanation of the question:_ Imagine a population in which individuals can develop different strategies for solving a particular problem. For ease of explanation, let's imagine the problem is something practical, and the solution is to design and build a particular tool that consists of different components. Imagine each component has a value that represents how much it contributes to solving the problem, and that an optimal solution to the problem requires a tool that combines several optimal components. Imagine individuals in this populations can have one of two possible strategies:\n",
    "\n",
    "1. Select one individual from the population who you want to learn from, spend a lot of time to perfectly acquire their solution (i.e., how to make their variant of the tool), and innovate that variant.\n",
    "2. Take in examples from many different individuals in the population, and try to combine their solutions (i.e., their variants of the tool).\n",
    "\n",
    "This research question is getting at a trade-off between accuracy of learning and diversity of input. An important assumption of your model should be that each individual has the same limited amount of time. Spending more time on learning one variant perfectly (as in strategy 1) means that you will be able to reproduce the variant more accurately, and understand better how it works (which should allow you to make more targeted innovations), but it comes at the cost of not being able to see a diverse set of solutions to the problem. Vice versa, taking in examples from different individuals in the population (strategy 2) has as an advantage that you'll be able to take in a diverse set of possible solutions to the problem (which should allow you to combine the good parts of the different solutions), but that comes at the cost of not being able to acquire/reproduce these perfectly (because you can't spend as much time learning about each individual solution).\n",
    "\n",
    "Specify, in bullet points, what the three major components of the model should consist of:\n",
    "- the agents\n",
    "- the interactions (agent-agent interactions and/or agent-environment interactions)\n",
    "- the environment\n",
    "\n",
    "If you think one of these three components is not relevant for answering this research question, write \"not relevant\" and briefly explain _why_ you believe this component is not relevant to the question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2228b445",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05be5d2e",
   "metadata": {},
   "source": [
    "**Exercise 9 (Coding question):**\n",
    "\n",
    "This question is about Mudd et al. (2022).\n",
    "\n",
    "Mudd et al. (2022) find that population size has an effect on the degree of lexical variability in the population, where larger populations lead to less lexical variability (i.e., more convergence). Their explanation for this effect is that this is a result of the feedback loop illustrated in Figure 12 in the paper (copy-pasted below):\n",
    "\n",
    "<img src=\"Fig_12_feedback_loop_Mudd_et_al.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "However, Mudd et al. (2022) do not show plots with the proportion of language game results to illustrate what this hypothesised feedback loop would look like in a single simulation. So that is what you are going to try and do below.\n",
    "\n",
    "**a)** Imagine you run a simulation contrasting a population of 5 agents with a population of 100 agents, and these simulations would behave according to the feedback loop described in Figure 12 of Mudd et al. (2022). Now imagine you would generate plots of the proportion of language game results (similar to Figures 7 and 8 from the Mudd et al. paper) for each of these populations. Describe in words what you think these plots should look like to illustrate the feedback loop. How would you expect the plots for the small and large population to be different? Explain why.\n",
    "\n",
    "\n",
    "**b)** Now actually run these simulations and generate the corresponding plots with the proportion of language game results, by adapting the final three code cells in this notebook. Instead of contrasting ```n_groups``` = 1 with ```n_groups``` = 10, your code should contrast ```n_agents = 5``` with  ```n_agents = 100```.\n",
    "Set the ```n_groups``` parameter to ```n_groups = 5``` (for both simulations).\n",
    "Run these simulations about 10 times, until you find an example case that looks like what you've described for part **a)** of this exercise. **Note** that this will definitely not happen every time you run the simulations and compare a single simulation with population size 5 with a single simulation with population size 100, but it will happen _sometimes_ (maybe around 1/3 of the time). The difference does not have to be very stark, but it does have to be visible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa2df43",
   "metadata": {},
   "source": [
    "## Necessary installations and imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eb162a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:38:22.771353Z",
     "start_time": "2022-10-21T17:38:18.491853Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install mesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42da3d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:38:58.339433Z",
     "start_time": "2022-10-21T17:38:58.335631Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "from math import sqrt\n",
    "import time\n",
    "from mesa import Agent, Model\n",
    "from mesa.datacollection import DataCollector\n",
    "from mesa.time import RandomActivation\n",
    "from mesa.batchrunner import BatchRunner, FixedBatchRunner\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a7e16",
   "metadata": {},
   "source": [
    "## Parameter settings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd229a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:52:49.002349Z",
     "start_time": "2022-10-21T17:52:48.999226Z"
    }
   },
   "outputs": [],
   "source": [
    "################# PARAMETER SETTINGS: ################# \n",
    "\n",
    "test_params = dict(\n",
    "    n_concepts=10, # int: number of concepts\n",
    "    n_bits=10,  # int: number of bits (determining length of forms and culturally-salient feature vectors)\n",
    "    n_agents=10, # int: number of agents in the population\n",
    "    n_groups=1,  # determines how many different semantic groups there are\n",
    "    initial_degree_of_overlap=0.9,  # degree of overlap between the form and meaning components\n",
    "    n_steps=2000  # number of timesteps to run the simulation for (called \"model stages\" in the paper)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea32b0fa",
   "metadata": {},
   "source": [
    "## Initialising the population and their language representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4a4ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:01.447675Z",
     "start_time": "2022-10-21T17:39:01.443658Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_skeleton(n_concepts, n_bits):\n",
    "    \"\"\" initiate language with n_concepts and n_bits\n",
    "    in the form {0: [meaning, form], 1: [meaning, from], ...}\n",
    "    the meaning and form components are initiated with None \"\"\"\n",
    "    skeleton_concept_meaning_form = {}\n",
    "    for n in range(n_concepts):\n",
    "        skeleton_concept_meaning_form[n] = [[None] * n_bits] * 2\n",
    "    return skeleton_concept_meaning_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee6141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:01.940913Z",
     "start_time": "2022-10-21T17:39:01.935913Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_create_meanings(n_concepts, n_bits, n_groups):\n",
    "    \"\"\" generate the meaning representation for each group\n",
    "    returns a dictionary with group: meaning representation\n",
    "    ex. {0: [[1, 1, 0, 1, 1], [0, 0, 0, 1, 0]], 1: [[0, 0, 0, 1, 1], [1, 1, 1, 1, 0]]} \"\"\"\n",
    "    group_meaning_dic = {}\n",
    "    for n in range(n_groups):\n",
    "        condition = False\n",
    "        while condition == False:\n",
    "            single_group_meaning_list = []\n",
    "            for concept in range(n_concepts):\n",
    "                single_group_meaning_list.append(random.choices([0, 1], k=n_bits))  # list of len n_components\n",
    "            if len(set(tuple(row) for row in single_group_meaning_list)) == len(\n",
    "                    single_group_meaning_list):\n",
    "                condition = True\n",
    "                group_meaning_dic[n] = single_group_meaning_list\n",
    "                \n",
    "    return group_meaning_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c434b9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:02.466538Z",
     "start_time": "2022-10-21T17:39:02.462509Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_add_meaning(agent, meaning_dic):\n",
    "    \"\"\" takes in the language skeleton and adds the meaning component depending on group of agent \"\"\"\n",
    "    counter = 0  # to keep track of which meaning component in meaning_dic values\n",
    "    for concept, meaning_form in agent.language_rep.items():\n",
    "        meaning_form[0] = meaning_dic[agent.group][counter]  # meaning_form[0] is the meaning only\n",
    "        counter += 1\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf725526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:03.317612Z",
     "start_time": "2022-10-21T17:39:03.312950Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_add_form(agent, initial_degree_of_overlap):\n",
    "    \"\"\" start with meaning representation and assign form representation\n",
    "    depending on the desired degree of overlap \"\"\"\n",
    "    for concept, meaning_form in agent.language_rep.items():\n",
    "        forms = []\n",
    "        for bit in meaning_form[0]:\n",
    "            my_choice = np.random.choice([True, False], p=[initial_degree_of_overlap, 1 - initial_degree_of_overlap])  # p = weights\n",
    "            if not my_choice:  # if my_choice == False\n",
    "                random_choice = np.random.choice([0, 1])\n",
    "                forms.append(random_choice)  # random choice 0 or 1 if False (random)\n",
    "            else:\n",
    "                forms.append(bit)  # append the same bit (iconic)\n",
    "        meaning_form[1] = forms\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ab483",
   "metadata": {},
   "source": [
    "## Running a language game and updating the agents' language representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4223046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:04.653571Z",
     "start_time": "2022-10-21T17:39:04.649680Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_game(sorted_agent_list):\n",
    "    \"\"\" takes agent list sorted by group\n",
    "    chooses and agent to be the producer \"\"\"\n",
    "    form_success = 0\n",
    "    meaning_success = 0\n",
    "    bit_update = 0\n",
    "\n",
    "    for a in sorted_agent_list:\n",
    "        what_is_updated = language_game_structure(a, sorted_agent_list)\n",
    "\n",
    "        if what_is_updated == \"3a\":\n",
    "            form_success += 1\n",
    "        elif what_is_updated == \"3b1\":\n",
    "            meaning_success += 1\n",
    "        else:  # \"3b2\"\n",
    "            bit_update += 1\n",
    "\n",
    "    language_game_stats = {\"form_success\": form_success, \"meaning_success\": meaning_success, \"bit_update\": bit_update}\n",
    "    return language_game_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6c997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:05.441093Z",
     "start_time": "2022-10-21T17:39:05.437212Z"
    }
   },
   "outputs": [],
   "source": [
    "def language_game_structure(producer, all_agents):\n",
    "    comprehender = random.choice(all_agents)\n",
    "    producer_concept_choice = random.choice(list(producer.language_rep))  # 1\n",
    "    form_match_answer = does_closest_form_match(producer, producer_concept_choice, comprehender)  # 2\n",
    "    if form_match_answer == False:  # 3b\n",
    "        meaning_match_answer = does_closest_meaning_match(producer, producer_concept_choice, comprehender)\n",
    "        if meaning_match_answer == False:  # 3b2\n",
    "            update_comprehender_concept(producer, producer_concept_choice, comprehender)\n",
    "            return \"3b2\"\n",
    "        else:  # 3b1\n",
    "            # None\n",
    "            return \"3b1\"\n",
    "    else:  # 3a\n",
    "        # None\n",
    "        return \"3a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f006c3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:05.765191Z",
     "start_time": "2022-10-21T17:39:05.760115Z"
    }
   },
   "outputs": [],
   "source": [
    "def does_closest_form_match(producer, producer_concept_choice, comprehender):\n",
    "    produced_form = producer.language_rep[producer_concept_choice][1]\n",
    "\n",
    "    distance_from_produced_form = {}\n",
    "    for concept, meaning_form in comprehender.language_rep.items():\n",
    "        # compare produced concept and all comp concepts, calculate distance between each\n",
    "        distance = sum([abs(prod_bit - comp_bit) for prod_bit, comp_bit in zip(produced_form, meaning_form[1])])\n",
    "        distance_from_produced_form[concept] = distance\n",
    "\n",
    "    min_distance = min(distance_from_produced_form.values())\n",
    "    comp_closest_form_list = [concept for concept, distance in distance_from_produced_form.items() if distance == min_distance]\n",
    "    comp_chosen_form = random.choice(comp_closest_form_list)  # because there can be multiple, randomly choose from list\n",
    "\n",
    "    return producer_concept_choice == comp_chosen_form  # returns True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28320c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:06.292324Z",
     "start_time": "2022-10-21T17:39:06.287989Z"
    }
   },
   "outputs": [],
   "source": [
    "def does_closest_meaning_match(producer, producer_concept_choice, comprehender):\n",
    "    produced_form = producer.language_rep[producer_concept_choice][1]\n",
    "\n",
    "    distance_from_produced_form = {}\n",
    "    for concept, meaning_form in comprehender.language_rep.items():\n",
    "        # compare produced concept and all comp concepts, calculate distance between each\n",
    "        distance = sum([abs(prod_bit - comp_bit) for prod_bit, comp_bit in zip(produced_form, meaning_form[0])])\n",
    "        distance_from_produced_form[concept] = distance\n",
    "    comp_closest_meaning = min(distance_from_produced_form, key=distance_from_produced_form.get)\n",
    "\n",
    "    return comp_closest_meaning == producer_concept_choice  # returns True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea13b3b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:06.861173Z",
     "start_time": "2022-10-21T17:39:06.856217Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_comprehender_concept(producer, producer_concept_choice, comprehender):\n",
    "    \"\"\" update comprehender form\n",
    "    compare all producer and comprehender form, find the ones that don't match\n",
    "    of the ones that don't match, choose one and flip this bit of the comprehender's form \"\"\"\n",
    "    comparison_list = ([(p_bit == c_bit) for p_bit, c_bit in zip(producer.language_rep[producer_concept_choice][1], comprehender.language_rep[producer_concept_choice][1])])\n",
    "    # to prevent case where correct concept has a match for form producer and comprehender\n",
    "    # this could happen if comprehender has 2 forms which both == form producer and the non-matching concept one gets chosen\n",
    "    if all(comparison_list) == True:\n",
    "        pass\n",
    "    else:\n",
    "        correctable_indexes = [i for i, comparison in enumerate(comparison_list) if comparison == False]  # get False indeces\n",
    "        chosen_index_to_correct = random.choice(correctable_indexes)\n",
    "        comprehender.language_rep[producer_concept_choice][1][chosen_index_to_correct] = abs(1 - (comprehender.language_rep[producer_concept_choice][1][chosen_index_to_correct]))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d382c",
   "metadata": {},
   "source": [
    "## Data-collector functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b1834c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:08.436405Z",
     "start_time": "2022-10-21T17:39:08.432068Z"
    }
   },
   "outputs": [],
   "source": [
    "# lexical variability\n",
    "def calculate_pop_lex_var(agent_list, n_concepts):\n",
    "    pairs_of_agents = itertools.combinations(agent_list, r=2)\n",
    "\n",
    "    pairs_lex_var = []\n",
    "\n",
    "    for pair in pairs_of_agents:\n",
    "        pair_lex_var = calculate_distance(pair, n_concepts)\n",
    "        pairs_lex_var.append(pair_lex_var)\n",
    "\n",
    "    pop_av_lex_var = sum(pairs_lex_var) / len(list(itertools.combinations(agent_list, r=2)))\n",
    "    return (pop_av_lex_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5662807a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:08.813072Z",
     "start_time": "2022-10-21T17:39:08.809632Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_distance(pair, n_concepts):\n",
    "    \"\"\" per concept per agent pair, distance = 0 if concepts are the same, distance = 1 if concepts are different\n",
    "    add up concept distances and divide by total number of concepts \"\"\"\n",
    "    concept_lex_var_total = 0  # list of distances between individual concepts (compare iconic agent a and iconic agent b)\n",
    "    for n in range(n_concepts):\n",
    "        if pair[0].language_rep[n][1] != pair[1].language_rep[n][1]:\n",
    "            concept_lex_var_total += 1  # if concepts don't match, add 1 to distance\n",
    "\n",
    "    pair_mean_lex_var = concept_lex_var_total / n_concepts\n",
    "    return pair_mean_lex_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5e6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:09.685187Z",
     "start_time": "2022-10-21T17:39:09.681612Z"
    }
   },
   "outputs": [],
   "source": [
    "# iconicity\n",
    "def calculate_degree_of_iconicity(agent):\n",
    "    concept_iconicity_vals = []\n",
    "\n",
    "    for concept, meaning_form in agent.language_rep.items():\n",
    "        comparison_list = ([(p_bit == c_bit) for p_bit, c_bit in zip(meaning_form[0], meaning_form[1])])  # returns True or False for each comparison\n",
    "        concept_iconicity_val = sum(comparison_list) / len(comparison_list)\n",
    "        concept_iconicity_vals.append(concept_iconicity_val)\n",
    "\n",
    "    mean_agent_iconicity = sum(concept_iconicity_vals) / len(concept_iconicity_vals)\n",
    "    return mean_agent_iconicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d18b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:10.356661Z",
     "start_time": "2022-10-21T17:39:10.353619Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_prop_iconicity(agent_list):\n",
    "    iconicity_list = [a.prop_iconicity for a in agent_list]\n",
    "    return sum(iconicity_list) / len(agent_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38642aec",
   "metadata": {},
   "source": [
    "## Defining the agent and the model as a whole (using the Mesa package):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313701ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:11.935199Z",
     "start_time": "2022-10-21T17:39:11.930960Z"
    }
   },
   "outputs": [],
   "source": [
    "class ContextAgent(Agent):\n",
    "    def __init__(self, unique_id, model, n_concepts, n_bits, n_groups):\n",
    "        super().__init__(unique_id, model)\n",
    "        self.group = random.choice(range(n_groups))\n",
    "        self.language_rep = language_skeleton(n_concepts, n_bits)  # dic = {concept: [[meaning], [form]}\n",
    "        self.prop_iconicity = None\n",
    "\n",
    "    def describe(self):\n",
    "        #print(f\"id = {self.unique_id}, prop iconicity = {self.prop_iconicity}, group = {self.group}, language = {self.language_rep}\")\n",
    "        print(self.language_rep)\n",
    "\n",
    "    def step(self):\n",
    "        self.prop_iconicity = calculate_degree_of_iconicity(self)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e5ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:13.033991Z",
     "start_time": "2022-10-21T17:39:13.020864Z"
    }
   },
   "outputs": [],
   "source": [
    "class ContextModel(Model):\n",
    "    \"\"\"A model with some number of agents.\"\"\"\n",
    "    def __init__(self, n_agents, n_concepts, n_bits, n_groups, initial_degree_of_overlap, n_steps, viz_on=False):\n",
    "        super().__init__()\n",
    "        self.placement_counter = 0\n",
    "        self.n_agents = n_agents\n",
    "        self.n_groups = n_groups\n",
    "        self.n_concepts = n_concepts\n",
    "        self.n_bits = n_bits\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "        self.current_step = 0\n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.running = True  # for server\n",
    "        self.group_meanings_dic = language_create_meanings(n_concepts, n_bits, n_groups) # set up language structure (maybe eventually a class)\n",
    "\n",
    "        self.width_height = int(sqrt(n_agents))\n",
    "        self.coordinate_list = list(itertools.product(range(self.width_height), range(self.width_height)))  # generate coordinates for grid\n",
    "\n",
    "        # language game successes and failures\n",
    "        self.lg_form_success = 0\n",
    "        self.lg_meaning_success = 0\n",
    "        self.lg_bit_update = 0\n",
    "        self.language_game_stats = {'form_success': None, 'meaning_success': None, 'bit_update': None}\n",
    "\n",
    "        # for datacollector\n",
    "        self.pop_iconicity = None\n",
    "        self.pop_lex_var = None\n",
    "        self.datacollector = DataCollector({'pop_iconicity': 'pop_iconicity',\n",
    "                                            'pop_lex_var': 'pop_lex_var',\n",
    "                                            'current_step': 'current_step',\n",
    "                                            'lg_form_success': 'lg_form_success',\n",
    "                                            'lg_meaning_success': 'lg_meaning_success',\n",
    "                                            'lg_bit_update': 'lg_bit_update'},\n",
    "                                           {'group': lambda agent: agent.group,\n",
    "                                            'language': lambda agent: agent.language_rep,\n",
    "                                            'prop iconicity': lambda agent: agent.prop_iconicity})\n",
    "\n",
    "        # create agents\n",
    "        for i in range(self.n_agents):\n",
    "            a = ContextAgent(i, self, self.n_concepts, self.n_bits, self.n_groups)  # make a new agent\n",
    "            language_add_meaning(a, self.group_meanings_dic)  # add meaning to language skeleton\n",
    "            language_add_form(a, initial_degree_of_overlap)  # add form to language skeleton\n",
    "\n",
    "            self.schedule.add(a)  # add agent to list of agents\n",
    "            a.prop_iconicity = calculate_degree_of_iconicity(a)\n",
    "\n",
    "        self.sorted_agents = sorted(self.schedule.agents, key=lambda agent: agent.group)  # sort agents by group\n",
    "\n",
    "    def collect_data(self):\n",
    "        self.pop_iconicity = calculate_prop_iconicity(self.schedule.agents)\n",
    "        self.pop_lex_var = calculate_pop_lex_var(self.schedule.agents, self.n_concepts)\n",
    "        self.current_step = self.current_step\n",
    "        self.lg_form_success = self.language_game_stats['form_success']\n",
    "        self.lg_meaning_success = self.language_game_stats['meaning_success']\n",
    "        self.lg_bit_update = self.language_game_stats['bit_update']\n",
    "        self.datacollector.collect(self)\n",
    "\n",
    "    def tests(self, a):\n",
    "        assert len(self.group_meanings_dic) == self.n_groups\n",
    "        assert len(self.group_meanings_dic[0]) == self.n_concepts\n",
    "        assert len(self.group_meanings_dic[0][0]) == self.n_bits\n",
    "        assert len(a.language_rep) == self.n_concepts\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\" Advance the model by one step \"\"\"\n",
    "        self.collect_data()  # set up = year 0\n",
    "\n",
    "        if self.current_step == 0:\n",
    "            self.tests(random.choice(self.schedule.agents))  # run tests on a random agent\n",
    "\n",
    "        self.current_step += 1\n",
    "        self.language_game_stats = language_game(self.sorted_agents)  # language game (only after the set up = year 0)\n",
    "\n",
    "        #if self.current_step == self.n_steps:\n",
    "        #    upgma_df = pd.DataFrame()\n",
    "\n",
    "        #    for i in self.schedule.agents:\n",
    "        #        for key, value in i.language_rep.items():\n",
    "        #            new_row = {'id': i.unique_id, 'concept': key, 'form': value[1]}\n",
    "        #            upgma_df = upgma_df.append(new_row, ignore_index=True)\n",
    "\n",
    "        #    upgma_df.to_csv(\"upgma_data.csv\")\n",
    "\n",
    "        self.schedule.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4860db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:40:22.626294Z",
     "start_time": "2022-10-21T17:40:19.074129Z"
    }
   },
   "outputs": [],
   "source": [
    "n_groups = 1\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "context_model = ContextModel(test_params[\"n_agents\"], test_params[\"n_concepts\"], test_params[\"n_bits\"], \n",
    "                             n_groups, test_params[\"initial_degree_of_overlap\"], test_params[\"n_steps\"])\n",
    "\n",
    "for i in range(test_params[\"n_steps\"]+1):  # set up = year 0 + x years\n",
    "    print(i)\n",
    "    context_model.step()\n",
    "\n",
    "print(\"Simulation(s) took %s minutes to run\" % round(((time.time() - start_time) / 60.), 2))  # ADDED BY MW\n",
    "\n",
    "df_model_output_1_group = context_model.datacollector.get_model_vars_dataframe()\n",
    "## alternative option for the agents is get_agent_vars_dataframe(), returns ['Step', 'AgentID', 'neighborhood', 'language', 'prop iconicity']\n",
    "\n",
    "csv_save_as = \"n_concepts_\"+str(test_params[\"n_concepts\"])+\"_n_bits_\"+str(test_params[\"n_bits\"])+\"_n_agents_\"+str(test_params[\"n_agents\"])+\"_n_groups_\"+str(n_groups)+\"_overlap_\"+str(test_params[\"initial_degree_of_overlap\"])+\"_n_steps_\"+str(test_params[\"n_steps\"])\n",
    "df_model_output_1_group = pd.DataFrame(df_model_output_1_group.to_records())  # gets rid of multiindex\n",
    "df_model_output_1_group.to_csv(f\"{csv_save_as}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900ef85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:39:21.652910Z",
     "start_time": "2022-10-21T17:39:17.788811Z"
    }
   },
   "outputs": [],
   "source": [
    "n_groups = 10\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "context_model = ContextModel(test_params[\"n_agents\"], test_params[\"n_concepts\"], test_params[\"n_bits\"], \n",
    "                             n_groups, test_params[\"initial_degree_of_overlap\"], test_params[\"n_steps\"])\n",
    "\n",
    "for i in range(test_params[\"n_steps\"]+1):  # set up = year 0 + x years\n",
    "    print(i)\n",
    "    context_model.step()\n",
    "\n",
    "print(\"Simulation(s) took %s minutes to run\" % round(((time.time() - start_time) / 60.), 2))  # ADDED BY MW\n",
    "\n",
    "df_model_output_10_groups = context_model.datacollector.get_model_vars_dataframe()\n",
    "## alternative option for the agents is get_agent_vars_dataframe(), returns ['Step', 'AgentID', 'neighborhood', 'language', 'prop iconicity']\n",
    "\n",
    "csv_save_as = \"n_concepts_\"+str(test_params[\"n_concepts\"])+\"_n_bits_\"+str(test_params[\"n_bits\"])+\"_n_agents_\"+str(test_params[\"n_agents\"])+\"_n_groups_\"+str(n_groups)+\"_overlap_\"+str(test_params[\"initial_degree_of_overlap\"])+\"_n_steps_\"+str(test_params[\"n_steps\"])\n",
    "df_model_output_10_groups = pd.DataFrame(df_model_output_10_groups.to_records())  # gets rid of multiindex\n",
    "df_model_output_10_groups.to_csv(f\"{csv_save_as}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae7ec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:40:31.637609Z",
     "start_time": "2022-10-21T17:40:27.477555Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# colormap\n",
    "cmap = plt.cm.viridis\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "\n",
    "# set up 2 column figure\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, constrained_layout=True)\n",
    "fig.set_size_inches(9,3)\n",
    "\n",
    "# FIG 1 GROUP EXAMPLE RUN\n",
    "# 1 group, 10 stages on ax0\n",
    "\n",
    "# Uncomment the line below if you want to load in your dataframe from a .csv file:\n",
    "# model_output = pd.read_csv(\"\", index_col=0)\n",
    "\n",
    "model_output = df_model_output_1_group\n",
    "\n",
    "model_output = model_output[['current_step', 'lg_form_success', 'lg_meaning_success', 'lg_bit_update']]\n",
    "model_output = model_output.rename(columns={\"lg_form_success\": \"form_success\", \"lg_meaning_success\": \"culturally_salient_features_success\", \"lg_bit_update\": \"update_bit\"})\n",
    "model_output = model_output.iloc[1:11]\n",
    "model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]] = model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]].div(10, axis=0)\n",
    "\n",
    "# https://www.python-graph-gallery.com/13-percent-stacked-barplot\n",
    "# From raw value to percentage\n",
    "totals = [i+j+k for i, j, k in zip(model_output['update_bit'], model_output['culturally_salient_features_success'], model_output['form_success'])]\n",
    "bit_bars = [i / j for i,j in zip(model_output['update_bit'], totals)]\n",
    "features_bars = [i / j for i,j in zip(model_output['culturally_salient_features_success'], totals)]\n",
    "form_bars = [i / j for i,j in zip(model_output['form_success'], totals)]\n",
    "\n",
    "steps = range(model_output[\"current_step\"].min(), model_output[\"current_step\"].max() + 1)  # min, max steps in df\n",
    "ax0.bar(steps, bit_bars, color=cmaplist[0], width=1, edgecolor=\"none\", label=\"bit update\")  # Create green Bars\n",
    "ax0.bar(steps, features_bars, bottom=bit_bars, color=cmaplist[128], width=1, edgecolor=\"none\", label=\"CS features success\")  # Create orange Bars\n",
    "ax0.bar(steps, form_bars, bottom=[i + j for i, j in zip(bit_bars, features_bars)], color=cmaplist[-1], width=1, edgecolor=\"none\", label=\"form success\")  # Create blue Bars\n",
    "\n",
    "# axes\n",
    "ax0.set_xlabel(\"Model stage\", fontsize=15)\n",
    "ax0.set_ylim(0,1)\n",
    "ax0.set_ylabel(\"Proportion\", fontsize=15)\n",
    "ax0.set_xticks(np.arange(1, 11, 1))\n",
    "\n",
    "\n",
    "# 1 group, 2000 stages on ax1\n",
    "\n",
    "# Uncomment the line below if you want to load in your dataframe from a .csv file:\n",
    "# model_output = pd.read_csv(\"\", index_col=0)\n",
    "\n",
    "model_output = df_model_output_1_group\n",
    "\n",
    "model_output = model_output[['current_step', 'lg_form_success', 'lg_meaning_success', 'lg_bit_update']]\n",
    "model_output = model_output.rename(columns={\"lg_form_success\": \"form_success\", \"lg_meaning_success\": \"culturally_salient_features_success\", \"lg_bit_update\": \"update_bit\"})\n",
    "model_output = model_output.drop([0])\n",
    "model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]] = model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]].div(10, axis=0)\n",
    "\n",
    "# add column with value for groups of 50 (1-50, 51-100, etc.)\n",
    "for index, row in model_output.iterrows():\n",
    "    model_output.at[index, \"hist_block\"] = int(index/50)\n",
    "\n",
    "model_output_grouped = model_output.groupby([\"hist_block\"]).mean()\n",
    "model_output_grouped[\"original_index\"] = model_output_grouped.index * 50\n",
    "model_output = model_output_grouped[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\", \"original_index\"]]\n",
    "\n",
    "# https://www.python-graph-gallery.com/13-percent-stacked-barplot\n",
    "# From raw value to percentage\n",
    "totals = [i+j+k for i, j, k in zip(model_output['update_bit'], model_output['culturally_salient_features_success'], model_output['form_success'])]\n",
    "bit_bars = [i / j for i,j in zip(model_output['update_bit'], totals)]\n",
    "features_bars = [i / j for i,j in zip(model_output['culturally_salient_features_success'], totals)]\n",
    "form_bars = [i / j for i,j in zip(model_output['form_success'], totals)]\n",
    "\n",
    "steps = range(int(model_output.index.min()), int(model_output.index.max() + 1))  # min, max steps in df\n",
    "ax1.bar(steps, bit_bars, color=cmaplist[0], width=1, edgecolor=\"none\", label=\"bit update\")  # Create green Bars\n",
    "ax1.bar(steps, features_bars, bottom=bit_bars, color=cmaplist[128], width=1, edgecolor=\"none\", label=\"CS features success\")  # Create orange Bars\n",
    "ax1.bar(steps, form_bars, bottom=[i + j for i, j in zip(bit_bars, features_bars)], color=cmaplist[-1], width=1, edgecolor=\"none\", label=\"form success\")  # Create blue Bars\n",
    "\n",
    "# legend\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "handles = [handles[2], handles[1], handles[0]]\n",
    "labels = [labels[2], labels[1], labels[0]]\n",
    "ax1.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# axes\n",
    "ax1.set_xlabel(\"Model stage\", fontsize=15)\n",
    "ax1.set_ylim(0,1)\n",
    "ax1.set_ylabel(\"\", fontsize=15)\n",
    "ax1.set_xticks(np.arange(0, 41, step=10))\n",
    "ax1.set_xticklabels([0,500,1000,1500,2000])\n",
    "\n",
    "plt.suptitle(\"1 group\", fontsize=18, x=0.4, y=1.1)\n",
    "\n",
    "plt.savefig(\"barplot_1group.png\", dpi=1000, bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "\n",
    "# FIG 10 GROUPS EXAMPLE RUN\n",
    "# set up 2 column figure\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, constrained_layout=True)\n",
    "fig.set_size_inches(9,3)\n",
    "\n",
    "# 10 groups, 10 stages on ax0\n",
    "\n",
    "# Uncomment the line below if you want to load in your dataframe from a .csv file:\n",
    "# model_output = pd.read_csv(\"\", index_col=0)\n",
    "\n",
    "model_output = df_model_output_10_groups\n",
    "\n",
    "model_output = model_output[['current_step', 'lg_form_success', 'lg_meaning_success', 'lg_bit_update']]\n",
    "model_output = model_output.rename(columns={\"lg_form_success\": \"form_success\", \"lg_meaning_success\": \"culturally_salient_features_success\", \"lg_bit_update\": \"update_bit\"})\n",
    "model_output = model_output.iloc[1:11]\n",
    "model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]] = model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]].div(10, axis=0)\n",
    "\n",
    "# https://www.python-graph-gallery.com/13-percent-stacked-barplot\n",
    "# From raw value to percentage\n",
    "totals = [i+j+k for i, j, k in zip(model_output['update_bit'], model_output['culturally_salient_features_success'], model_output['form_success'])]\n",
    "bit_bars = [i / j for i,j in zip(model_output['update_bit'], totals)]\n",
    "features_bars = [i / j for i,j in zip(model_output['culturally_salient_features_success'], totals)]\n",
    "form_bars = [i / j for i,j in zip(model_output['form_success'], totals)]\n",
    "\n",
    "steps = range(model_output[\"current_step\"].min(), model_output[\"current_step\"].max() + 1)  # min, max steps in df\n",
    "ax0.bar(steps, bit_bars, color=cmaplist[0], width=1, edgecolor=\"none\", label=\"bit update\")  # Create green Bars\n",
    "ax0.bar(steps, features_bars, bottom=bit_bars, color=cmaplist[128], width=1, edgecolor=\"none\", label=\"CS features success\")  # Create orange Bars\n",
    "ax0.bar(steps, form_bars, bottom=[i + j for i, j in zip(bit_bars, features_bars)], color=cmaplist[-1], width=1, edgecolor=\"none\", label=\"form success\")  # Create blue Bars\n",
    "\n",
    "# axes\n",
    "ax0.set_xlabel(\"Model stage\", fontsize=15)\n",
    "ax0.set_ylim(0,1)\n",
    "ax0.set_ylabel(\"Proportion\", fontsize=15)\n",
    "ax0.set_xticks(np.arange(1, 11, 1))\n",
    "\n",
    "# 10 groups, 2000 stages on ax1\n",
    "\n",
    "# Uncomment the line below if you want to load in your dataframe from a .csv file:\n",
    "# model_output = pd.read_csv(\"\", index_col=0)\n",
    "\n",
    "model_output = df_model_output_10_groups\n",
    "\n",
    "model_output = model_output[['current_step', 'lg_form_success', 'lg_meaning_success', 'lg_bit_update']]\n",
    "model_output = model_output.rename(columns={\"lg_form_success\": \"form_success\", \"lg_meaning_success\": \"culturally_salient_features_success\", \"lg_bit_update\": \"update_bit\"})\n",
    "model_output = model_output.drop([0])\n",
    "model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]] = model_output[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\"]].div(10, axis=0)\n",
    "\n",
    "# add column with value for groups of 50 (1-50, 51-100, etc.)\n",
    "for index, row in model_output.iterrows():\n",
    "    model_output.at[index, \"hist_block\"] = int(index/50)\n",
    "\n",
    "model_output_grouped = model_output.groupby([\"hist_block\"]).mean()\n",
    "model_output_grouped[\"original_index\"] = model_output_grouped.index * 50\n",
    "model_output = model_output_grouped[[\"form_success\", \"culturally_salient_features_success\", \"update_bit\", \"original_index\"]]\n",
    "\n",
    "# https://www.python-graph-gallery.com/13-percent-stacked-barplot\n",
    "# From raw value to percentage\n",
    "totals = [i+j+k for i, j, k in zip(model_output['update_bit'], model_output['culturally_salient_features_success'], model_output['form_success'])]\n",
    "bit_bars = [i / j for i,j in zip(model_output['update_bit'], totals)]\n",
    "features_bars = [i / j for i,j in zip(model_output['culturally_salient_features_success'], totals)]\n",
    "form_bars = [i / j for i,j in zip(model_output['form_success'], totals)]\n",
    "\n",
    "steps = range(int(model_output.index.min()), int(model_output.index.max() + 1))  # min, max steps in df\n",
    "ax1.bar(steps, bit_bars, color=cmaplist[0], width=1, edgecolor=\"none\", label=\"bit update\")  # Create green Bars\n",
    "ax1.bar(steps, features_bars, bottom=bit_bars, color=cmaplist[128], width=1, edgecolor=\"none\", label=\"CS features success\")  # Create orange Bars\n",
    "ax1.bar(steps, form_bars, bottom=[i + j for i, j in zip(bit_bars, features_bars)], color=cmaplist[-1], width=1, edgecolor=\"none\", label=\"form success\")  # Create blue Bars\n",
    "\n",
    "# legend\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "handles = [handles[2], handles[1], handles[0]]\n",
    "labels = [labels[2], labels[1], labels[0]]\n",
    "ax1.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# axes\n",
    "ax1.set_xlabel(\"Model stage\", fontsize=15)\n",
    "ax1.set_ylim(0,1)\n",
    "ax1.set_ylabel(\"\", fontsize=15)\n",
    "ax1.set_xticks(np.arange(0, 41, step=10))\n",
    "ax1.set_xticklabels([0,500,1000,1500,2000])\n",
    "\n",
    "plt.suptitle(\"10 groups\", fontsize=18, x=0.4, y=1.1)\n",
    "\n",
    "plt.savefig(\"barplot_10groups.png\", dpi=1000, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727b1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba12b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd1f2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ecd5fde",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
