{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79bda934",
   "metadata": {},
   "source": [
    "# ABCM Computer lab 3: Population effects & Cultural evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72068b7",
   "metadata": {},
   "source": [
    "This notebook contains a reproduction of the model by Cuskley et al. (2018) in python.\n",
    "Below follows a brief walk-through of the code.\n",
    "\n",
    "To load the code into your notebook, make sure to run each of the code cells below in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1bdf48",
   "metadata": {},
   "source": [
    "First, let's import the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa74ad74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:40:29.510684Z",
     "start_time": "2022-10-05T13:40:28.168947Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32d49f",
   "metadata": {},
   "source": [
    "We start by setting a bunch of parameters.\n",
    "Unfortunately, the code takes a while to run. To make it feasible to run some simulations in a reasonable amount of time, the code below therefore makes a number of changes compared to the Cuskley et al. (2018) parameter settings. See the parameter settings below; the comment after each parameter states what setting Cuskley et al. (2018) used.\n",
    "\n",
    "These measures should hopefully allow you to run the relevant simulations in around 15 min per condition. \n",
    "\n",
    "Have a look at each of the parameters below, and check whether you understand which parameter or condition described in Cuskley et al. (2018) they correspond to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74830a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:40:31.433926Z",
     "start_time": "2022-10-05T13:40:31.430545Z"
    }
   },
   "outputs": [],
   "source": [
    "n_runs = 2  # int: number of independent simulation runs. Cuskley et al. (2018) used 100\n",
    "pop_sizes = [20, 100]  # list of ints: initial pop sizes. Cuskley et al. (2018) used 20 for small and 100 for large pop\n",
    "n_lemmas = 14  # int: number of lemmas. Cuskley et al. (2018) used 28\n",
    "n_tokens = 250  # int: number of tokens in vocabulary. Cuskley et al. seem to have used 500 (in C++ implementation)\n",
    "n_inflections = 6  # int: number of inflections. Cuskley et al. (2018) used 12\n",
    "zipf_exponent = 2  # int: exponent used to create Zipfian frequency distribution. Cuskley et al., 2018 used 2\n",
    "k_proficiency = 250  # int: token threshold that determines proficiency. Cuskley et al. (2018) used 1500\n",
    "r_replacement = 0.001  # float: replacement rate for turnover condition. Cuskley et al. (2018) used 0.001.\n",
    "# At every interaction, there is an r chance that a randomly selected learner will be replaced by a new learner\n",
    "g_growth = 0.001  # float: growth rate for growth condition. Cuskley et al. (2018) used 0.001.\n",
    "# At every interaction, there's a g chance that a new learner will be *added* to the population\n",
    "replacement = True  # Boolean: determines whether this simulation includes replacement (turnover)\n",
    "growth = False  # Boolean; determines whether this simulation includes growth\n",
    "t_timesteps = 5000  # int: number of timesteps to run per simulation. Cuskley et al. (2018) used 10,000\n",
    "d_memory = 100  # int: no. of timesteps after which agent forgets lemma-inflection pairing. Cuskley et al. used 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f893fe0",
   "metadata": {},
   "source": [
    "We start with a function that can create a vocabulary array that contains n_tokens tokens of n_lemmas types, with a Zipfian frequency distribution.\n",
    "\n",
    "Skim the function and check whether you understand what it's doing and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b04ad30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:40:33.506775Z",
     "start_time": "2022-10-05T13:40:33.500136Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_vocab(n_lemmas, zipf_exponent, n_tokens):\n",
    "\t\"\"\"\n",
    "\tGenerates a vocabulary (numpy array of n_tokens tokens of n_lemmas types, with Zipfian frequency distribution)\n",
    "\t:param n_lemmas: int: number of lemmas\n",
    "\t:param zipf_exponent: int: exponent used to create Zipfian frequency distribution. Cuskley et al., 2018 used 2\n",
    "\t:param n_tokens: int: number of tokens in vocabulary. Cuskley et al. seem to have used 500 (in C++ implementation)\n",
    "\t:return: (1) numpy array containing n_tokens tokens of n_lemmas types; (2) numpy array with log frequency per lemma\n",
    "\t\"\"\"\n",
    "\tlemma_indices = np.arange(n_lemmas)  # create numpy array with index for each lemma\n",
    "\tzipf_dist = np.random.zipf(zipf_exponent, size=n_lemmas)  # create Zipfian frequency distribution for lemmas\n",
    "\tzipf_dist_in_probs = np.divide(zipf_dist, np.sum(zipf_dist))\n",
    "\tzipf_dist_for_n_tokens = np.multiply(zipf_dist_in_probs, n_tokens)\n",
    "\tzipf_dist_for_n_tokens = np.ceil(zipf_dist_for_n_tokens)  # Round UP, so that we get *at least* n_tokens in vocab\n",
    "\tvocabulary = np.array([])\n",
    "\tfor i in range(len(lemma_indices)):\n",
    "\t\tlemma_index = lemma_indices[i]\n",
    "\t\tlemma_freq = zipf_dist_for_n_tokens[i]\n",
    "\t\tvocabulary = np.concatenate((vocabulary, np.array([lemma_index for x in range(int(lemma_freq))])))\n",
    "\tfor j in range(2):  # doing this twice because sth weird w/ np.delete() function: doesn't always delete all indices\n",
    "\t\t# (possibly to do with later index going out of bounds once previous indices have been deleted)\n",
    "\t\tif vocabulary.shape[0] > n_tokens:  # if vocab is larger than n_tokens, randomly remove excess tokens\n",
    "\t\t\trandom_indices = np.random.choice(np.arange(vocabulary.shape[0]), size=(vocabulary.shape[0] - n_tokens))\n",
    "\t\t\tvocabulary = np.delete(vocabulary, random_indices)\n",
    "\tnp.random.shuffle(vocabulary)  # finally, shuffle the array so that tokens of lemmas occur in random order\n",
    "\tvocabulary = vocabulary.astype(int)\n",
    "\treturn vocabulary, np.log(zipf_dist_in_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db41723a",
   "metadata": {},
   "source": [
    "The rest of the code is divided up into the following four classes: (In object-oriented programming languages like Python, a class is essentially a collection of attributes and functions that belong together.)\n",
    "\n",
    "- ```Inflection```\n",
    "- ```Lemma```\n",
    "- ```Agent```\n",
    "- ```Simulation```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31748338",
   "metadata": {},
   "source": [
    "## Inflection and Lemma classes:\n",
    "\n",
    "We start with the Inflection class. This class defines an inflection as paired with a lemma.\n",
    "\n",
    "Skim the Inflection class and check whether you understand what it's doing and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1049704e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:40:35.985039Z",
     "start_time": "2022-10-05T13:40:35.981599Z"
    }
   },
   "outputs": [],
   "source": [
    "class Inflection:\n",
    "\t\"\"\"\n",
    "\tClass which defines an inflection as paired with a lemma\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, interactions=0, successes=0, weight=np.nan, last_interaction=np.nan):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialises Inflection object\n",
    "\t\t:param interactions: int: number of interactions agents has had about this lemma\n",
    "\t\t:param successes: int: no. of successful interactions agent has had about this lemma\n",
    "\t\t:param weight: float: no. of successes / no. of interactions. Initialised as NAN for pairing is non-existent\n",
    "\t\t:param last_interaction: int: timestep when the pairing was last encountered, later compared against d_memory\n",
    "\t\t\"\"\"\n",
    "\t\tself.interactions = interactions\n",
    "\t\tself.successes = successes\n",
    "\t\tself.weight = weight\n",
    "\t\tself.last_interaction = last_interaction\n",
    "\n",
    "\tdef empty_inflection(self):\n",
    "\t\t\"\"\"\n",
    "\t\tEmpties the inflection by resetting each of its attributes; used by Lemma.purge() method when memory window\n",
    "\t\t(i.e., d_memory timesteps) has elapsed since last interaction with this inflection\n",
    "\t\t:return: resets each of the inflection object's attributes; doesn't return anything\n",
    "\t\t\"\"\"\n",
    "\t\tself.interactions = 0\n",
    "\t\tself.successes = 0\n",
    "\t\tself.weight = np.nan\n",
    "\t\tself.last_interaction = np.nan\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd67468",
   "metadata": {},
   "source": [
    "Next is the Lemma class, which can update the inflections of a given lemma depending on the outcomes of interactions between agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e9ea1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:40:38.503017Z",
     "start_time": "2022-10-05T13:40:38.491754Z"
    }
   },
   "outputs": [],
   "source": [
    "class Lemma:\n",
    "\t\"\"\"\n",
    "\tLemma class\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, lemma_index, tokens, seen, inflections):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialises Lemma object\n",
    "\t\t:param lemma_index: int: index of the lemma\n",
    "\t\t:param tokens: int: number of times the agent has encountered this lemma\n",
    "\t\t:param seen: Boolean: whether the agent has encountered this lemma before\n",
    "\t\t:param inflections: dictionary with keys: \"interactions\", \"successes\", \"weight\", \"last_interaction\"\n",
    "\t\t\"\"\"\n",
    "\t\tself.index = lemma_index\n",
    "\t\tself.tokens = tokens\n",
    "\t\tself.seen = seen\n",
    "\t\tself.inflections = inflections\n",
    "\n",
    "\tdef reset_lemma(self):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialises/resets all attributes of the lemma object\n",
    "\t\t:param self:\n",
    "\t\t:return:\n",
    "\t\t\"\"\"\n",
    "\t\tself.tokens = 0\n",
    "\t\tself.seen = False\n",
    "\t\tself.inflections = [Inflection() for i in range(n_inflections)]  # n_inflections is global variable\n",
    "\n",
    "\tdef add_inflection(self, infl_index, outcome, timestep):\n",
    "\t\t\"\"\"\n",
    "\t\tAdds an inflection to the lemma (as a result of an interaction in which that inflection was used),\n",
    "\t\twith weight depending on the outcome of the interaction (success or failure) and the number of\n",
    "\t\tprevious interaction in which this inflection was used\n",
    "\t\t:param infl_index: int: index of the inflection in self.inflections\n",
    "\t\t:param outcome: int: 1 if success (i.e., if receiver has lemma-inflection pairing in inventory), 0 if failure\n",
    "\t\t:param timestep: int: timestep of current interaction\n",
    "\t\t:return: updates attributes of lemma object; doesn't return anything\n",
    "\t\t\"\"\"\n",
    "\t\tself.seen = True\n",
    "\t\tself.tokens = 1\n",
    "\t\tself.inflections[infl_index].interactions = 1\n",
    "\t\tself.inflections[infl_index].successes = outcome\n",
    "\t\tself.inflections[infl_index].weight = float(outcome) / float(self.inflections[infl_index].interactions)\n",
    "\t\tself.inflections[infl_index].last_interaction = timestep\n",
    "\n",
    "\tdef update_inflection(self, infl_index, outcome, timestep):\n",
    "\t\t\"\"\"\n",
    "\t\tUpdates a lemma-inflection pairing based on the outcome of an interaction\n",
    "\t\t:param infl_index: int: index of the inflection in self.inflections\n",
    "\t\t:param outcome: int: 1 if success (i.e., if receiver has lemma-inflection pairing in inventory), 0 if failure\n",
    "\t\t:param timestep: int: timestep of current interaction\n",
    "\t\t:return: updates attributes of lemma object; doesn't return anything\n",
    "\t\t\"\"\"\n",
    "\t\tself.tokens += 1\n",
    "\t\tself.inflections[infl_index].interactions += 1\n",
    "\t\tself.inflections[infl_index].successes += outcome\n",
    "\t\tself.inflections[infl_index].weight = float(self.inflections[infl_index].successes) / float(\n",
    "\t\t\tself.inflections[infl_index].interactions)\n",
    "\t\tself.inflections[infl_index].last_interaction = timestep\n",
    "\n",
    "\tdef has_inflection(self, infl_index):\n",
    "\t\t\"\"\"\n",
    "\t\tChecks whether agent already has a specific inflection (indicated by infl_index) for this lemma\n",
    "\t\t:param infl_index: int: index of the inflection in self.inflections\n",
    "\t\t:return: Boolean: True if agent already has this specific inflection for this lemma, False if not\n",
    "\t\t\"\"\"\n",
    "\t\tif self.inflections[infl_index].interactions > 0:\n",
    "\t\t\treturn True\n",
    "\t\telse:\n",
    "\t\t\treturn False\n",
    "\n",
    "\tdef get_best(self):\n",
    "\t\t\"\"\"\n",
    "\t\tFinds indices of inflections with highest weight for this lemma\n",
    "\t\t:return: int: index of highest-weighted inflection. If multiple with max weight, one is selected randomly\n",
    "\t\t\"\"\"\n",
    "\t\tweight_array = np.array([self.inflections[i].weight for i in range(len(self.inflections))])\n",
    "\t\tif np.isnan(weight_array).all() == True:  # if only NANs in the array, just choose an index randomly\n",
    "\t\t\tmax_index = np.random.choice(np.arange(\n",
    "\t\t\t\tlen(self.inflections)))\n",
    "\t\telse:\n",
    "\t\t\tmax_weight = np.nanmax(weight_array)\n",
    "\t\t\tmax_indices = np.where(weight_array == max_weight)[0]\n",
    "\t\t\tmax_index = np.random.choice(max_indices)\n",
    "\t\treturn max_index\n",
    "\n",
    "\tdef has_any_inflection(self):\n",
    "\t\t\"\"\"\n",
    "\t\tChecks whether this lemma has any inflections yet (this is considered to be the case if any of the possible\n",
    "\t\tinflections have come up in an interaction about this lemma before).\n",
    "\t\t:return: Boolean: False if lemma object doesn't have any inflections yet; True if it does\n",
    "\t\t\"\"\"\n",
    "\t\tinteractions_per_inflection = np.array([self.inflections[i].interactions for i in range(len(self.inflections))])\n",
    "\t\tif np.sum(interactions_per_inflection) == 0:\n",
    "\t\t\treturn False\n",
    "\t\telif np.sum(interactions_per_inflection) > 0:\n",
    "\t\t\treturn True\n",
    "\n",
    "\tdef purge(self, timestep):\n",
    "\t\t\"\"\"\n",
    "\t\tResets lemma-inflection pairing if memory window (d_memory) has elapsed\n",
    "\t\t:param timestep: int: timestep of current interaction\n",
    "\t\t:return: updates self.inflections attribute of lemma object; doesn't return anything\n",
    "\t\t\"\"\"\n",
    "\t\tfor i in range(len(self.inflections)):\n",
    "\t\t\tif (timestep - self.inflections[\n",
    "\t\t\t\ti].last_interaction) > d_memory:  # d_memory is global variable; see parameter settings\n",
    "\t\t\t\tself.inflections[i].empty_inflection()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a870c",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "In this exercise, we're going to have a look at what a Lemma object looks like, and how it can be used.\n",
    "\n",
    "In order to initialise a Lemma object, we have to specify several input arguments:\n",
    "- ```lemma_index```\n",
    "- ```tokens```\n",
    "- ```seen```\n",
    "- ```inflections```\n",
    "\n",
    "The values of these attributes don't really matter for the purposes of the current exercise, so you can just initialise your Lemma object with random values. \n",
    "\n",
    "Note that the ```inflections``` input argument expects a list of Inflection objects. To create these, you can do:\n",
    "\n",
    "```[Inflection() for i in range(n_inflections)]```\n",
    "\n",
    "This creates a list of Inflection objects with default values.\n",
    "\n",
    "To print the attributes of an object, you can use:\n",
    "\n",
    "```print(object_name.__dict__)```\n",
    "\n",
    "So, for example, assuming you have created a Lemma object named ```my_lemma```, you can do:\n",
    "```print(my_lemma.__dict__)```\n",
    "in order to inspect it.\n",
    "\n",
    "\n",
    "**a) Write code that does the following:**\n",
    "- Create a Lemma object\n",
    "- write a for-loop that uses the Lemma's .update_inflection() method 10 times, where at each timestep:\n",
    "    - an inflection index is selected randomly from range n_inflections\n",
    "    - an outcome value is selected randomly from the options [0, 1] (representing failure and success, respectively)\n",
    "    - the Lemma object's .update_inflection() method is called with the input arguments generated above (timestep is not relevant for this exercise, but you can just set it to the index of your for-loop, if you feel like it)\n",
    "    - inspect the Lemma object and how it changes. This requires not just printing the lemma object, but also printing each of the Inflection objects in the lemma's self.inflections attribute (again using ```print(object_name.__dict__))```\n",
    "  \n",
    "  \n",
    "**b) How is the weight of a given inflection calculated each time the .update_inflection() method is called?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81063f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e45593e9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80b69b9a",
   "metadata": {},
   "source": [
    "## Agent class:\n",
    "\n",
    "Next, we have the Agent class, which contains all the attributes/properties of an agent (e.g., their vocabulary, how many tokens they've seen in their life so far, whether that makes them a type-generaliser or a token-generaliser, etc.), and all the functions (named \"methods\" if we're talking about a class) that allow the agent to interact and update their attributes/properties based on the content and outcome of that interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbdec85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:40:42.828828Z",
     "start_time": "2022-10-05T13:40:42.811911Z"
    }
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\t\"\"\"\n",
    "\tAgent class\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, tokens=0, k_threshold=k_proficiency, memory_window=d_memory, type_generalise=False,\n",
    "\t\t\t\t is_active=False):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialises Agent object\n",
    "\t\t:param tokens: int: number of tokens seen by the agent in total. Initial value: 0\n",
    "\t\t:param k_threshold: int: token threshold that determines proficiency. Default: k_proficiency (=global variable)\n",
    "\t\t:param memory_window: int: no. of timesteps after which agent forgets pairing. Default: d_memory (=global var.)\n",
    "\t\t:param type_generalise: Boolean: False = agent is token-generaliser; True = type-generaliser. Initial: False\n",
    "\t\t:param is_active: Boolean: Initial value: False. Agent's status gets changed to active when it gets added to pop\n",
    "\t\t\"\"\"\n",
    "\t\tself.tokens = tokens\n",
    "\t\tself.k_threshold = k_threshold\n",
    "\t\tself.memory_window = memory_window\n",
    "\t\tself.type_generalise = type_generalise\n",
    "\t\tself.is_active = is_active\n",
    "\t\tempty_inflections = [Inflection() for i in range(n_inflections)]  # used for initiliasing empty vocab below\n",
    "\t\tself.vocabulary = [Lemma(0, 0, False, empty_inflections) for x in range(n_lemmas)]  # initialise empty vocab\n",
    "\n",
    "\tdef reset_agent(self):\n",
    "\t\t\"\"\"\n",
    "\t\tResets agent's attributes to initial/empty\n",
    "\t\t:return: resets agent's attributes; doesn't return anything\n",
    "\t\t\"\"\"\n",
    "\t\tself.is_active = True\n",
    "\t\tself.tokens = 0\n",
    "\t\tself.type_generalise = False\n",
    "\t\tfor lemma in self.vocabulary:\n",
    "\t\t\tlemma.reset_lemma()\n",
    "\n",
    "\tdef has_inflections(self, lemma_index):\n",
    "\t\t\"\"\"\n",
    "\t\tChecks whether agent has any inflections for a particular lemma (indicated by lemma_index)\n",
    "\t\t:param lemma_index: int: index of particular Lemma object in self.vocabulary\n",
    "\t\t:return: Boolean: True if agent has any inflections for this particular lemma, False if not\n",
    "\t\t\"\"\"\n",
    "\t\treturn self.vocabulary[lemma_index].has_any_inflection()\n",
    "\n",
    "\tdef update_lemma(self, lemma_index, infl_index, outcome, timestep):\n",
    "\t\t\"\"\"\n",
    "\t\tUpdate the entry for a particular lemma\n",
    "\t\t:param lemma_index: int: index of the lemma (in the agent's self.vocabulary attribute)\n",
    "\t\t:param infl_index: int: index of the inflection\n",
    "\t\t:param outcome: int: 1 if success (i.e., if receiver has lemma-inflection pairing in inventory), 0 if failure\n",
    "\t\t:param timestep: int: timestep of current interaction\n",
    "\t\t:return: updates lemma in agent's vocabulary; doesn't return anything\n",
    "\t\t\"\"\"\n",
    "\t\tself.tokens += 1\n",
    "\t\t# If lemma-inflection pairing exists, update the weighting according to the outcome of the interaction:\n",
    "\t\tif self.vocabulary[lemma_index].has_inflection(infl_index):\n",
    "\t\t\tself.vocabulary[lemma_index].update_inflection(infl_index, outcome, timestep)\n",
    "\t\t# If lemma-inflection pairing doesn't exist yet, create it:\n",
    "\t\telse:\n",
    "\t\t\tself.vocabulary[lemma_index].add_inflection(infl_index, outcome, timestep)\n",
    "\t\t# Purge the inflections of the lemma (i.e., remove inflections that haven't been used for d_memory timesteps)\n",
    "\t\tself.vocabulary[lemma_index].purge(timestep)\n",
    "\t\t# Finally, set agent's self.type_generalise attribute depending on how many tokens it has encountered in total\n",
    "\t\tif self.tokens > self.k_threshold:\n",
    "\t\t\tself.type_generalise = True\n",
    "\t\telse:\n",
    "\t\t\tself.type_generalise = False\n",
    "\n",
    "\tdef get_best(self, lemma_index):\n",
    "\t\t\"\"\"\n",
    "\t\tGet best (i.e., heighest-weighted) inflection for this lemma\n",
    "\t\t:param lemma_index: int: index of the lemma (in the agent's self.vocabulary attribute)\n",
    "\t\t:return: int: index of best (i.e., heighest-weighted) inflection for this lemma\n",
    "\t\t\"\"\"\n",
    "\t\treturn self.vocabulary[lemma_index].get_best()\n",
    "\n",
    "\tdef get_token_best(self):\n",
    "\t\t\"\"\"\n",
    "\t\tToken-generalise: Look across vocab and extend rule that was used most frequently across all tokens of any type\n",
    "\t\t:return: int: index of inflection used across most *tokens*\n",
    "\t\t\"\"\"\n",
    "\t\tmax_tokens = np.zeros(n_inflections)\n",
    "\t\tfor lemma_index in range(len(self.vocabulary)):\n",
    "\t\t\tfor i in range(n_inflections):\n",
    "\t\t\t\tmax_tokens[i] += self.vocabulary[lemma_index].inflections[i].successes\n",
    "\t\tmax_successes = np.amax(max_tokens)\n",
    "\t\tmax_token_indices = np.where(max_tokens == max_successes)[0]\n",
    "\t\tmax_index = np.random.choice(max_token_indices)\n",
    "\t\treturn max_index\n",
    "\n",
    "\tdef get_type_best(self):\n",
    "\t\t\"\"\"\n",
    "\t\tType-generalise: Look across vocab and extend the rule which applies to the most types in agent's vocab\n",
    "\t\t:return: int: index of inflection used across most *types*\n",
    "\t\t\"\"\"\n",
    "\t\tmax_types = np.zeros(n_inflections)\n",
    "\t\tfor lemma_index in range(len(self.vocabulary)):\n",
    "\t\t\tbest_inflection = self.vocabulary[lemma_index].get_best()\n",
    "\t\t\tmax_types[best_inflection] += 1\n",
    "\t\tmax_values = np.amax(max_types)\n",
    "\t\tmax_token_indices = np.where(max_types == max_values)[0]\n",
    "\t\tmax_index = np.random.choice(max_token_indices)\n",
    "\t\treturn max_index\n",
    "\n",
    "\tdef generate_inflection(self):\n",
    "\t\t\"\"\"\n",
    "\t\tIf a lemma has no inflections, generate an inflection based on generalisation processes\n",
    "\t\t:return: int: index of newly generated (/generalised) inflection\n",
    "\t\t\"\"\"\n",
    "\t\tinflection_utterance = np.nan\n",
    "\t\t# If self.type_generalise is True (= when agent has exceeded k_threshold), find inflection used for most types\n",
    "\t\tif self.type_generalise:\n",
    "\t\t\tinflection_utterance = self.get_type_best()\n",
    "\t\t\t# If preferred generalisation process doesn't provide inflection, try other method (token-generalise)\n",
    "\t\t\tif np.isnan(inflection_utterance):\n",
    "\t\t\t\tinflection_utterance = self.get_token_best()\n",
    "\t\t# If self.type_generalise is False (=agent hasn't reached k_threshold yet) find inflection used for most tokens\n",
    "\t\telse:\n",
    "\t\t\tinflection_utterance = self.get_token_best()\n",
    "\t\t\t# If preferred generalisation process doesn't provide inflection, try other method (type-generalise)\n",
    "\t\t\tif np.isnan(inflection_utterance):\n",
    "\t\t\t\tinflection_utterance = self.get_type_best()\n",
    "\t\t# If agent has no inflections in vocabulary, they will choose a random inflection from the predefined set\n",
    "\t\tif np.isnan(inflection_utterance):\n",
    "\t\t\tinflection_utterance = np.random.choice(np.arange(n_inflections))\n",
    "\t\treturn inflection_utterance\n",
    "\n",
    "\tdef receive(self, lemma_index, infl_index, timestep):\n",
    "\t\t\"\"\"\n",
    "\t\tTake inflection in as receiver and update lemmas in vocabulary accordingly\n",
    "\t\t:param lemma_index: int: index of the lemma (in the agent's self.vocabulary attribute)\n",
    "\t\t:param infl_index: int: index of the inflection\n",
    "\t\t:param timestep: int: timestep of current interaction\n",
    "\t\t:return: Boolean: 1 if interaction is success (= lemma-inflection pairing in receiver's vocab), 0 otherwise\n",
    "\t\t\"\"\"\n",
    "\t\t# If agent has any inflections for this lemma:\n",
    "\t\tif self.has_inflections(lemma_index):\n",
    "\t\t\t# If the agent has this particular inflection for this lemma --- no matter the weight --- return success\n",
    "\t\t\tif self.vocabulary[lemma_index].has_inflection(infl_index):\n",
    "\t\t\t\tself.update_lemma(lemma_index, infl_index, 1, timestep)\n",
    "\t\t\t\treturn 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.update_lemma(lemma_index, infl_index, 0, timestep)\n",
    "\t\t\t\treturn 0\n",
    "\t\t# If agent doesn't have any inflections for this lemma, generate inflection based on generalisation processes\n",
    "\t\telse:\n",
    "\t\t\tguess = self.generate_inflection()\n",
    "\t\t\t# If the newly generated inflection matches the inflection in question, return success:\n",
    "\t\t\tif guess == infl_index:\n",
    "\t\t\t\tself.update_lemma(lemma_index, infl_index, 1, timestep)\n",
    "\t\t\t\treturn 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.update_lemma(lemma_index, infl_index, 0, timestep)\n",
    "\t\t\t\treturn 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217851a",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "\n",
    "In this exercise, we're going to create two Agent objects and have them interact with each other. \n",
    "\n",
    "When you create an Agent object, you *can* specify a number of input arguments. However, the Agent class is defined in such a way that each of these input arguments has a default value. This means that you can simply create a \"default\" Agent using:\n",
    "\n",
    "``` my_agent = Agent()```\n",
    "\n",
    "\n",
    "**a) Write code to do the following:**\n",
    "- Create two agent objects called ```agent_1``` and ```agent_2```\n",
    "- Write a for-loop to loop through the following steps 10 times:\n",
    "    - Randomly choose a lemma from range(n_lemmas), and print the chosen lemma\n",
    "    - Randomly assign the role of producer to one of the agents, and the role of receiver to the other agent\n",
    "    - Make the producer agent produce an utterance (i.e., an inflection for the lemma that was chosen above) using the Agent's ```.get_best()``` method, and print the utterance\n",
    "    - Print the values in the receiver's vocabulary for the lemma-inflection pairing that was uttered, *before* running the .receive method\n",
    "    - Make the receiver agent update their vocabulary based on the utterance received, using the Agent's ```.receive()``` method. Save the outcome of this interaction (= output of the ```.receive()``` method) in a variable and print it\n",
    "    - Print the values in the receiver's vocabulary for the lemma-inflection pairing that was uttered, *after* running the .receive method, and inspect how they've changed.\n",
    "    \n",
    "    \n",
    "**b) Do you notice any pattern in which inflections the agents use across the different lemmas? If so, try to explain this pattern.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebf223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad23d7fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2130512",
   "metadata": {},
   "source": [
    "## Simulation class:\n",
    "\n",
    "That brings us to the final class: Simulation. This class allows us to run a batch of simulation runs given the parameter settings specified at the top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ce1aef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:40:46.762432Z",
     "start_time": "2022-10-05T13:40:46.739324Z"
    }
   },
   "outputs": [],
   "source": [
    "class Simulation:\n",
    "\t\"\"\"\n",
    "\tSimulation class\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, pop_size):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialises simulation object with self.pop_size, self.population and self.running_popsize\n",
    "\t\t:param pop_size: int: population size\n",
    "\t\t\"\"\"\n",
    "\t\tself.pop_size = pop_size\n",
    "\t\tself.population = [Agent() for x in range(3000)]  # Create initial pop, plus \"dormant\" agents to allow for growth\n",
    "\t\tself.running_popsize = pop_size  # int: keeps track of the changing population size in the growth condition\n",
    "\t\tself.n_interactions = pop_size  # int: no. of interactions per timestep. Cuskley et al. used same as pop size\n",
    "\t\tself.vocabulary, self.log_freqs_per_lemma = generate_vocab(n_lemmas, zipf_exponent, n_tokens)  # generate vocab\n",
    "\t\tself.all_tokens = 0  # Keeps track of total number of tokens that have come up in interactions across timesteps\n",
    "\t\tself.global_inflections = np.zeros(n_inflections)  # Keeps track of frequency of each inflection throughout the simulation\n",
    "\t\tself.global_counts = np.zeros(n_lemmas)  # Keeps track of the frequency of each lemma throughout the simulation\n",
    "\t\tself.pop_size_column = np.zeros(n_runs*t_timesteps*n_lemmas)\n",
    "\t\tself.r_column = np.zeros(n_runs*t_timesteps*n_lemmas)\n",
    "\t\tself.tstep_column = np.zeros(n_runs*t_timesteps*n_lemmas)\n",
    "\t\tself.lemma_column = np.zeros(n_runs*t_timesteps*n_lemmas)\n",
    "\t\tself.log_freq_column = np.zeros(n_runs * t_timesteps * n_lemmas)\n",
    "\t\tself.infl_column = np.zeros(n_runs*t_timesteps*n_lemmas)\n",
    "\t\tself.vocab_entropy_column = np.zeros(n_runs*t_timesteps*n_lemmas)\n",
    "\t\tself.meaning_entropy_column = np.zeros(n_runs*t_timesteps*n_lemmas)\n",
    "\n",
    "\tdef interaction(self, producer, receiver, lemma, current_timestep):\n",
    "\t\t\"\"\"\n",
    "\t\tRun single interaction between producer and receiver\n",
    "\t\t:param producer: int: index of producer agent in self.population\n",
    "\t\t:param receiver: int: index of receiver agent in self.population\n",
    "\t\t:param lemma: int: index of lemma in agent.vocabulary\n",
    "\t\t:param current_timestep: int: current timestep\n",
    "\t\t:return: updates the lemma in the producer's and receiver's vocabulary based on how the interaction goes,\n",
    "\t\tand self.global_inflections, which keeps track of frequency of each inflection throughout the simulation;\n",
    "\t\tdoesn't return anything\n",
    "\t\t\"\"\"\n",
    "\t\tif self.population[producer].has_inflections(lemma):\n",
    "\t\t\tutterance = self.population[producer].get_best(lemma)\n",
    "\t\t\tresult = self.population[receiver].receive(lemma, utterance, current_timestep)\n",
    "\t\telse:\n",
    "\t\t\tutterance = self.population[producer].generate_inflection()\n",
    "\t\t\tresult = self.population[receiver].receive(lemma, utterance, current_timestep)\n",
    "\t\tself.population[producer].update_lemma(lemma, utterance, result, current_timestep)\n",
    "\t\tself.global_inflections[utterance] += 1\n",
    "\n",
    "\tdef replace_agent(self):\n",
    "\t\t\"\"\"\n",
    "\t\tReplace an agent in turnover condition. Randomly selects an agent from the population and resets its attributes\n",
    "\t\t(equivalent to removing the selected agent and adding a new agent)\n",
    "\t\t:return: updates self.population by resetting the attributes of the selected agent; doesn't return anything\n",
    "\t\t\"\"\"\n",
    "\t\t# Generate random float from uniform dist. [0.0, 1.0); if float <= r_replacement probability: reset random agent\n",
    "\t\tif np.random.random() <= r_replacement:\n",
    "\t\t\tchosen_one_index = np.random.choice(np.arange(self.running_popsize - 1))\n",
    "\t\t\tself.population[chosen_one_index].reset_agent()\n",
    "\n",
    "\tdef add_agent(self):\n",
    "\t\t\"\"\"\n",
    "\t\tAdd agent to population in growth condition by setting one of the \"dormant\" agents' .is_active attribute to True\n",
    "\t\t:return: updates self.population by adding a new agent (by setting .is_active to True); doesn't return anything\n",
    "\t\t\"\"\"\n",
    "\t\tif np.random.random() <= g_growth:\n",
    "\t\t\tself.running_popsize += 1\n",
    "\t\t\t# Take next of \"dormant\" agents in line and turn its .is_active attribute to True:\n",
    "\t\t\tself.population[self.running_popsize-1].is_active = True\n",
    "\n",
    "\tdef timestep(self, current_timestep):\n",
    "\t\t\"\"\"\n",
    "\t\tRuns through 1 timestep in simulation. Each timestep consists of self.n_interactions interactions.\n",
    "\t\tCuskley et al. (2018) used n_interactions = pop_size\n",
    "\t\t:param current_timestep: int: current timestep\n",
    "\t\t:return: Updates attributes of population and its agents based on the interactions they go through,\n",
    "\t\tand whether the replacement and growth conditions are turned on or off (see global variables)\n",
    "\t\t\"\"\"\n",
    "\t\tvocab_index = 0\n",
    "\t\tfor i in range(self.n_interactions):\n",
    "\t\t\t# Randomly select producer and receiver agent:\n",
    "\t\t\tproducer_index = np.random.choice(np.arange(self.running_popsize-1))\n",
    "\t\t\treceiver_index = np.random.choice(np.arange(self.running_popsize-1))\n",
    "\t\t\t# Make sure producer and receiver are not the same agent:\n",
    "\t\t\twhile producer_index == receiver_index:\n",
    "\t\t\t\treceiver_index = np.random.choice(np.arange(self.running_popsize-1))\n",
    "\t\t\t# If we've reached the end of the vocabulary array, re-shuffle it:\n",
    "\t\t\tif vocab_index >= (n_tokens-1):\n",
    "\t\t\t\tnp.random.shuffle(self.vocabulary)\n",
    "\t\t\t\tvocab_index = 0\n",
    "\t\t\ttopic = self.vocabulary[vocab_index]\n",
    "\t\t\tself.interaction(producer_index, receiver_index, topic, current_timestep)\n",
    "\t\t\tif growth:  # growth is global variable (Boolean)\n",
    "\t\t\t\tself.add_agent()\n",
    "\t\t\tif replacement:  # growth is global variable (Boolean)\n",
    "\t\t\t\tself.replace_agent()\n",
    "\t\t\tself.global_counts[topic] += 1\n",
    "\t\t\tself.all_tokens += 1\n",
    "\t\t\tvocab_index += 1\n",
    "\n",
    "\tdef inflections_in_vocab(self):\n",
    "\t\t\"\"\"\n",
    "\t\tCounts total number of inflections present in population\n",
    "\t\t:return: int: total number of inflections present in population\n",
    "\t\t\"\"\"\n",
    "\t\tinfl_counts = np.zeros(n_inflections)\n",
    "\t\ttotal_inflections = 0.\n",
    "\t\t# First, create array which counts for each inflection how many agents in population have that inflection\n",
    "\t\tfor l in range(n_lemmas):\n",
    "\t\t\tfor a in range(self.running_popsize):\n",
    "\t\t\t\tif self.population[a].has_inflections(l):\n",
    "\t\t\t\t\tbest_infl = self.population[a].get_best(l)\n",
    "\t\t\t\t\tinfl_counts[best_infl] += 1\n",
    "\t\t# Then, get the total number of inflections which has a count >0 (i.e. that is used by at least 1 agent in pop)\n",
    "\t\tfor i in range(n_inflections):\n",
    "\t\t\tif infl_counts[i] > 0:\n",
    "\t\t\t\ttotal_inflections += 1\n",
    "\t\treturn total_inflections\n",
    "\n",
    "\tdef get_entropy(self, probability_array):\n",
    "\t\t\"\"\"\n",
    "\t\tCalculates the entropy from a list of probablities/frequencies\n",
    "\t\t:param probability_array: 1D numpy array containing probabilities (i.e., should sum to 1.0)\n",
    "\t\t:return: float: entropy\n",
    "\t\t\"\"\"\n",
    "\t\tentropy = 0.\n",
    "\t\tfor p in probability_array:\n",
    "\t\t\tif p > 0.:\n",
    "\t\t\t\tentropy += p * np.log2(1./p)\n",
    "\t\treturn entropy\n",
    "\n",
    "\tdef vocabulary_entropy(self):\n",
    "\t\t\"\"\"\n",
    "\t\tCalculates entropy of inflection across the vocabulary, H_v\n",
    "\t\t:return: float: H_v\n",
    "\t\t\"\"\"\n",
    "\t\t# how predictable is the inflection of any given lemma?\n",
    "\t\t# for each lemma\n",
    "\t\tinflection_probs = np.zeros(n_inflections)\n",
    "\t\tdenominator = 0.\n",
    "\t\tfor l in range(n_lemmas):\n",
    "\t\t\tfor a in range(self.running_popsize):\n",
    "\t\t\t\tif self.population[a].vocabulary[l].has_any_inflection():\n",
    "\t\t\t\t\tdenominator += 1\n",
    "\t\t\t\t\tbest_infl = self.population[a].get_best(l)\n",
    "\t\t\t\t\tinflection_probs[best_infl] += 1\n",
    "\t\tinflection_probs = np.divide(inflection_probs, denominator)\n",
    "\t\treturn self.get_entropy(inflection_probs)\n",
    "\n",
    "\tdef meaning_entropy(self, lemma):\n",
    "\t\t\"\"\"\n",
    "\t\tCalculates entropy of the inflection for a specific lemma, H_l\n",
    "\t\t:param lemma: int: index of lemma that should be conditioned on\n",
    "\t\t:return: float: H_l\n",
    "\t\t\"\"\"\n",
    "\t\t# what is the probability of each inflection given this lemma?\n",
    "\t\tinflections = np.zeros(n_inflections)\n",
    "\t\tlemma_count = 0.\n",
    "\t\tfor a in range(self.running_popsize):\n",
    "\t\t\tif self.population[a].has_inflections(lemma):\n",
    "\t\t\t\tbest_infl = self.population[a].get_best(lemma)\n",
    "\t\t\t\tinflections[best_infl] += 1.\n",
    "\t\t\t\tlemma_count += 1.\n",
    "\t\tinflection_probs = np.divide(inflections, lemma_count)\n",
    "\t\treturn self.get_entropy(inflection_probs)\n",
    "\n",
    "\tdef single_run(self, run_number, counter):\n",
    "\t\t\"\"\"\n",
    "\t\tRuns a single simulation. Each run is t_timesteps long (Cuskley et al., 2018 used 10,000)\n",
    "\t\t:param run_number: int: index of current run\n",
    "\t\t:return: Updates the Simulation object's attributes (specifically the results arrays); doesn't return anything\n",
    "\t\t\"\"\"\n",
    "\t\tfor t in range(t_timesteps):\n",
    "\t\t\tif t % 500 == 0:  # after every 50 timesteps, print the current timestep, so we know where we're at:\n",
    "\t\t\t\tprint(\"t: \"+str(t))\n",
    "\t\t\tself.timestep(t)\n",
    "\t\t\ttotal_inflections = self.inflections_in_vocab()\n",
    "\t\t\tif t == t_timesteps-1:\n",
    "\t\t\t\tvocab_entropy = self.vocabulary_entropy()\n",
    "\t\t\tfor lemma_index in range(n_lemmas):\n",
    "\t\t\t\tself.pop_size_column[counter] = self.pop_size\n",
    "\t\t\t\tself.r_column[counter] = run_number\n",
    "\t\t\t\tself.tstep_column[counter] = t\n",
    "\t\t\t\tself.lemma_column[counter] = lemma_index\n",
    "\t\t\t\tself.log_freq_column[counter] = self.log_freqs_per_lemma[lemma_index]\n",
    "\t\t\t\tself.infl_column[counter] = total_inflections\n",
    "\t\t\t\tif t == t_timesteps-1:\n",
    "\t\t\t\t\tself.vocab_entropy_column[counter] = vocab_entropy\n",
    "\t\t\t\t\tself.meaning_entropy_column[counter] = self.meaning_entropy(lemma_index)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.vocab_entropy_column[counter] = np.nan\n",
    "\t\t\t\t\tself.meaning_entropy_column[counter] = np.nan\n",
    "\t\t\t\tcounter += 1\n",
    "\t\tprint(\"self.running_popsize at end of simulation:\")\n",
    "\t\tprint(self.running_popsize)\n",
    "\t\treturn counter\n",
    "\n",
    "\tdef multi_runs(self):\n",
    "\t\t\"\"\"\n",
    "\t\tRuns multiple runs of the simulation\n",
    "\t\t:return: pandas dataframe containing all results\n",
    "\t\t\"\"\"\n",
    "\t\tfor i in range(self.pop_size):\n",
    "\t\t\tself.population[i].is_active = True\n",
    "\t\tcounter = 0\n",
    "\t\tfor r in range(n_runs):\n",
    "\t\t\tprint('')\n",
    "\t\t\tprint(\"r: \"+str(r))\n",
    "\t\t\t# First, reset self.all_tokens, self.global_inflections, and self.global_counts before starting a new run:\n",
    "\t\t\tself.all_tokens = 0\n",
    "\t\t\tself.global_inflections = np.zeros(n_inflections)\n",
    "\t\t\tself.global_counts = np.zeros(n_lemmas)\n",
    "\t\t\t# Then, run a new run:\n",
    "\t\t\tcounter = self.single_run(r, counter)\n",
    "\t\t# After all runs have finished, turn the numpy arrays with results into a pandas dataframe:\n",
    "\t\tresults_dict = {\"pop_size\": self.pop_size_column,\n",
    "\t\t\t\t\t\t\"run\": self.r_column,\n",
    "\t\t\t\t\t\t\"timestep\": self.tstep_column,\n",
    "\t\t\t\t\t\t\"lemma\": self.lemma_column,\n",
    "\t\t\t\t\t\t\"log_freq\": self.log_freq_column,\n",
    "\t\t\t\t\t\t\"n_inflections\": self.infl_column,\n",
    "\t\t\t\t\t\t\"vocab_entropy\": self.vocab_entropy_column,\n",
    "\t\t\t\t\t\t\"meaning_entropy\": self.meaning_entropy_column}\n",
    "\t\tresults_dataframe = pd.DataFrame(results_dict)\n",
    "\t\treturn results_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e469ce4",
   "metadata": {},
   "source": [
    "## Final functions for running simulations and plotting results\n",
    "\n",
    "We have now seen all the classes that the code for this model consists of. In addition to those, we also need a function that can run simulations for several population sizes, and combine their results into one big dataframe, which also gets saved as a pickle file (to your current working directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce94adf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:40:48.442794Z",
     "start_time": "2022-10-05T13:40:48.438620Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_multi_sizes(pop_sizes):\n",
    "\t\"\"\"\n",
    "\tRuns simulations for each pop_size in pop_sizes\n",
    "\t:param pop_sizes: list of ints specifying the different population sizes that should be run\n",
    "\t:return: pandas dataframe containing simulation results for all pop_sizes in pop_sizes\n",
    "\t\"\"\"\n",
    "\tstart_time = time.time()\n",
    "\tframes = []\n",
    "\t# First run simulations for each of the pop_sizes:\n",
    "\tfor pop_size in pop_sizes:\n",
    "\t\tprint('')\n",
    "\t\tprint(\"pop_size is:\")\n",
    "\t\tprint(pop_size)\n",
    "\t\tsimulation = Simulation(pop_size)\n",
    "\t\tresults_dataframe = simulation.multi_runs()\n",
    "\t\tframes.append(results_dataframe)\n",
    "\t\tprint(\"Simulation(s) took %s minutes to run\" % round(((time.time() - start_time) / 60.), 2))\n",
    "\t# Then combine the results for each of the pop_sizes into one big dataframe, so that they can be plotted together:\n",
    "\tcombined_dataframe = pd.concat(frames, ignore_index=True)\n",
    "\tcombined_dataframe.to_pickle(\"./results_\"+\"n_runs_\"+str(n_runs)+\"_tsteps_\" + str(t_timesteps) +\"_replacement_\"+str(replacement)+\"_growth_\"+str(growth)+\"_n_lem_\"+str(n_lemmas)+\"_n_infl_\"+str(n_inflections)+\"_n_tok_\"+str(n_tokens)+\".pkl\")\n",
    "\treturn combined_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b1e1f8",
   "metadata": {},
   "source": [
    "Finally, we need a couple of plotting functions. The resulting plots also get saved as pdfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382957ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:40:50.317776Z",
     "start_time": "2022-10-05T13:40:50.311391Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_vocab_entropy(results_df):\n",
    "\tsns.set_style(\"darkgrid\")\n",
    "\twith sns.color_palette(\"deep\", 2):\n",
    "\t\tsns.displot(data=results_df, x=\"vocab_entropy\", hue=\"pop_size\", kind=\"kde\", fill=True)\n",
    "\tplt.savefig(\"./Hv_plot_\"+\"n_runs_\"+str(n_runs)+\"_tsteps_\" + str(t_timesteps) +\"_replacement_\"+str(replacement)+\"_growth_\"+str(growth)+\"_n_lem_\"+str(n_lemmas)+\"_n_infl_\"+str(n_inflections)+\"_n_tok_\"+str(n_tokens)+\".pdf\")\n",
    "\n",
    "\n",
    "def plot_meaning_entropy_by_freq(results_df):\n",
    "\tsns.set_style(\"darkgrid\")\n",
    "\twith sns.color_palette(\"deep\", 2):\n",
    "\t\tsns.lineplot(data=results_df, x=\"log_freq\", y=\"meaning_entropy\", hue=\"pop_size\")\n",
    "\tplt.savefig(\"./Hl_plot_\"+\"n_runs_\"+str(n_runs)+\"_tsteps_\" + str(t_timesteps) +\"_replacement_\"+str(replacement)+\"_growth_\"+str(growth)+\"_n_lem_\"+str(n_lemmas)+\"_n_infl_\"+str(n_inflections)+\"_n_tok_\"+str(n_tokens)+\".pdf\")\n",
    "\n",
    "\n",
    "def plot_active_inflections_over_time(results_df):\n",
    "\tsns.set_style(\"darkgrid\")\n",
    "\twith sns.color_palette(\"deep\", 2):\n",
    "\t\tsns.lineplot(data=results_df, x=\"timestep\", y=\"n_inflections\", hue=\"pop_size\")\n",
    "\tplt.savefig(\"./Inflections_plot_\"+\"n_runs_\"+str(n_runs)+\"_tsteps_\" + str(t_timesteps) +\"_replacement_\"+str(replacement)+\"_growth_\"+str(growth)+\"_n_lem_\"+str(n_lemmas)+\"_n_infl_\"+str(n_inflections)+\"_n_tok_\"+str(n_tokens)+\".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4a970",
   "metadata": {},
   "source": [
    "**Exercise 3:**\n",
    "\n",
    "Have a look at each of the plotting functions above, and which measures from the results_dataframe they visualise.\n",
    "\n",
    "Are all measures that are reported in the figures in Cuskley et al. (2018) represented here? If not, explain what is missing, and what that missing measure captures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba372444",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3a87b74",
   "metadata": {},
   "source": [
    "### Example of how to run simulation:\n",
    "\n",
    "Below is an example of how to run a simulation for each population size in the pop_sizes parameter, and to save and print the resulting dataframe. **Note** that the code cell below temporarily decreases the number of timesteps (as defined by the ```t_timesteps``` parameter at the top of the code), because the code cell below is just meant as a quick example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447041a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:05:54.084583Z",
     "start_time": "2022-10-05T13:05:36.004051Z"
    }
   },
   "outputs": [],
   "source": [
    "t_timesteps = 100\n",
    "\n",
    "results_dataframe = run_multi_sizes(pop_sizes)\n",
    "print('')\n",
    "print(\"results_dataframe is:\")\n",
    "print(results_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de62c6b",
   "metadata": {},
   "source": [
    "The simulation results have been saved in a Pandas dataframe. To extract only the results of the final timestep, for example, you can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4307b67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:06:03.753285Z",
     "start_time": "2022-10-05T13:06:03.734608Z"
    }
   },
   "outputs": [],
   "source": [
    "final_timestep_results = results_dataframe[results_dataframe[\"timestep\"]==t_timesteps-1]\n",
    "print(\"final_timestep_results are:\")\n",
    "print(final_timestep_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8ff07b",
   "metadata": {},
   "source": [
    "Just resetting the ```t_timesteps``` parameter to its original value, before we move on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a9f61d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:06:43.655280Z",
     "start_time": "2022-10-05T13:06:43.652845Z"
    }
   },
   "outputs": [],
   "source": [
    "t_timesteps = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77326e5",
   "metadata": {},
   "source": [
    "### Plotting the results:\n",
    "\n",
    "Now that we have a dataframe containing simulation results two different population sizes, we can plot the results using the three plotting functions defined above, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f89a6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:06:45.824376Z",
     "start_time": "2022-10-05T13:06:45.444145Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plot_vocab_entropy(final_timestep_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d6afb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:06:47.558681Z",
     "start_time": "2022-10-05T13:06:47.188553Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plot_meaning_entropy_by_freq(final_timestep_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3149845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T13:06:51.878000Z",
     "start_time": "2022-10-05T13:06:48.349659Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plot_active_inflections_over_time(results_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557cd813",
   "metadata": {},
   "source": [
    "**Exercise 4:**\n",
    "\n",
    "For this exercise, we need results of a simulation that is similar to Cuskley et al.'s \"turnover\" condition. Do you need to make any changes to the ```replacement``` parameter or ```growth``` parameter at the top of the notebook in order to do that? If not, feel free to re-use the ```combined_dataframe``` generated above.\n",
    "\n",
    "Compare your own \"vocab_entropy\" plot with Fig. 2A of Cuskley et al. (2018).\n",
    "\n",
    "**a)** What does the measure $H_{v}$ or \"vocab_entropy\" represent? \n",
    "\n",
    "**b)** What does the measure $H_{l}$ or \"meaning_entropy\" represent? And what does it mean to have an $H_{l}$ of 0.0?\n",
    "\n",
    "**c)** Does your own \"vocab_entropy\" plot look similar to Cuskley et al.'s Fig. 2A? Describe both the meaningful similarities (if any) and differences (if any). If you find meaningful differences, try to explain what the cause of those might be (based on what you know about the different parameter settings used here compared to Cuskley et al., 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a2866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e04da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94985ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb908cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6c23e12",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "938a9f3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8fbb145",
   "metadata": {},
   "source": [
    "**Exercise 5:**\n",
    "\n",
    "For this exercise, run a simulation that is similar to Cuskley et al.'s \"growth\" condition. Do you need to make any changes to the ```replacement``` parameter or ```growth``` parameter at the top of the notebook in order to do that?\n",
    "\n",
    "**a)** Which subfigure in Cuskley et al. (2018) does your \"active_inflections_over_time\" plot correspond to?\n",
    "\n",
    "**b)** For this particular model and these simulations, how would you go about deciding how many timesteps you should ideally look it? When is it ok to stop running a simulation?\n",
    "\n",
    "**c)** Looking at your own \"active_inflections_over_time\" plot, and comparing it to the corresponding subfigure in Cuskley et al. (2018), do you believe that you have run your simulations for enough timesteps? If not, explain why not. Or if you find that you cannot tell based on your plot, also explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edd7ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f215a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d9e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a4b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c671605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f2da4a6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64e0efa2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27be8ccf",
   "metadata": {},
   "source": [
    "**BONUS Exercise 6 (only if you have time left):**\n",
    "\n",
    "Read through the Simulation class more closely, and based on that, try to answer the following question:\n",
    "\n",
    "Under which of the following conditions would you predict the run time of a simulation to increase most strongly?\n",
    "1. If you double the number of lemmas in the vocabulary\n",
    "2. If you double the number agents in the population\n",
    "3. If you double the number of timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18cd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
